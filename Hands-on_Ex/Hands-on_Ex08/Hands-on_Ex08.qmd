---
title: "Hands-on Exercise 8"
author: "Dexter Wan"
date: "October 22, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  freeze: true
---

## Description

Learning to build hedonic pricing models by using GWR methods in R.

### Changelog

23 Oct 24: Completed Hands-on Exercise 8.

## Importing Data and setting up R Environment

First I will load the relevant packages needed.

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```

Now I will import the geospatial data.

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

```{r}
st_crs(mpsz)
```

The CRS is using the wrong EPSG code. SVY21 EPSG is 3414.

```{r}
mpsz_svy21 = st_transform(mpsz, 3414)
```

Now I will import the aspatial data.

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
glimpse(condo_resale)
```

Now we convert the aspatial data into an sf object.

```{r}
condo_resale.sf = st_as_sf(condo_resale, 
                           coords = c("LONGITUDE", "LATITUDE"),
                           crs=4326) %>%
  st_transform(crs = 3414)
head(condo_resale.sf)
```

## Exploratory Data Analysis (EDA)

Plotting the distribution of SELLING_PRICE using EDA.

```{r}
ggplot(data = condo_resale.sf, aes(x = `SELLING_PRICE`))+
  geom_histogram(bins = 20, color = "black", fill = "orange")
```

The figure shows a right-skewed distribution, suggesting that more units were sold at lower prices. We can normalise this distribution using log transformation.

```{r}
condo_resale.sf = condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE)) 

ggplot(data = condo_resale.sf, aes(x = `LOG_SELLING_PRICE`))+
  geom_histogram(bins = 20, color = "black", fill = "orange")
```

Now lets plot a histogram of different variables.

```{r}
#| fig-width: 12
#| fig-height: 12
AREA_SQM = ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="orange")

AGE = ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_CBD = ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_CHILDCARE = ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="orange")

PROX_ELDERLYCARE = ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_URA_GROWTH_AREA = ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_HAWKER_MARKET = ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_KINDERGARTEN = ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_MRT = ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_PARK = ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_PRIMARY_SCH = ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="orange")

PROX_TOP_PRIMARY_SCH = ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="orange")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

Now we can draw a statistical point map to see the distribution of condo resale prices in Singapore.

```{r}
#| fig-width: 12
tmap_mode("view")

tm_shape(mpsz_svy21) + 
  #mpsz cant plot onto view mode due to incorrect polygons, check.and.fix to solve   issue
  tmap_options(check.and.fix = TRUE) + 
  tm_polygons() +
tm_shape(condo_resale.sf)+
  tm_dots(col = "SELLING_PRICE", alpha = 0.6, style = "quantile")+
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")
```

## Hedonic Pricing Modelling

Now I will build hedonic pricing models for condo resale units using *lm().*

### Simple Linear Regression Method

First, we will build a simple linear regression model with SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable. Then a summary can be printed with *summary()* or *anova().*

```{r}
condo.slr = lm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
anova(condo.slr)
summary(condo.slr)
```

Through the *summary()* output, we can reveal the formula of SELLING_PRICE to be:

```         
y = -258121.1 + 14719x
```

Since the p-value is \< 0.05, we can reject the null hypothesis that mean is a good estimator of SELLING_PRICE, and instead that the simple linear regression model is a better estimator. We can visualise the best fit curve on a scatterplot.

```{r}
ggplot(data = condo_resale.sf,
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`))+
  geom_point() +
  geom_smooth(method = lm) #indicates lm as the method
```

We can spot some outliers in with higher selling prices.

### Multiple Linear Regression Method

First, we must ensure that independent variables are not highly correlated. We can do this through a correlation matrix. We can do this using *pairs()* or *corrplot().*

```{r}
#| fig-width: 12
#| fig-height: 12
corrplot(cor(condo_resale[,5:23]), diag = FALSE, order = "AOE", method = "number",
         tl.cex = 0.7)
```

We do see that FREEHOLD and LEASEHOLD_99YEAR are highly correlated. We should include only 1 of the two in our subsequent model building. We shall exclude LEASEHOLD_99YEAR

### Hedonic Pricing Model using Multiple Linear Regression Method

Now we can use *lm()* again, but include all other independent variables.

```{r}
condo.mlr = lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD 
               + PROX_CHILDCARE+ PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA 
               + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + PROX_MRT 
               + PROX_PARK + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH 
               + PROX_SHOPPING_MALL + PROX_SUPERMARKET + PROX_BUS_STOP 
               + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
               data = condo_resale.sf)
summary(condo.mlr)
```

One thing to note here is that not all p-values of every variable is \<0.05. We should revise this and remove the non-significant variables.

```{r}
condo.mlr1 = lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD 
               + PROX_CHILDCARE+ PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA 
               + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH 
               + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS 
               + FAMILY_FRIENDLY + FREEHOLD,
               data = condo_resale.sf)
summary(condo.mlr1)
```

### Preparing Publication Quality Table: oslrr method

Now we can calibrate the revised model using *ols_regress().*

```{r}
ols_regress(condo.mlr1)
```

### Preparing Publication Quality Table: gtsummary method

We can also present it using *tbl_regression()* from ***gtsummary.***

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

We can add the model statistics using either *add_glance_table()* or *add_glance_source_note().*

```{r}
tbl_regression(condo.mlr1, intercept = TRUE) %>%
  add_glance_source_note(label = list(sigma ~ "\U03C3"),
                         include = c(r.squared, adj.r.squared, 
                                     AIC, statistic, p.value, sigma))
```

Now I will test for multicolinearity using *ols_vif_tol()*

```{r}
ols_vif_tol(condo.mlr1)
```

As all VIF values are below 10, we can conclude that there are no signs of multicollinearity. Now we can test for Non-linearity

```{r}
ols_plot_resid_fit(condo.mlr1)
```

As most of the data points are scattered along the 0 line, we can conclude the relationship between dependent and independent variables are linear. Now we can perform normality assumption test.

```{r}
ols_plot_resid_hist(condo.mlr1)
```

We can see that our regression model resembles a normal distribution. We can re-verify this with a statistical test method.

```{r}
ols_test_normality(condo.mlr1)
```

Now we can test for spatial autocorrelation.

```{r}
#Combine residuals into original sf
condo_resale.res.sf = cbind(condo_resale.sf, condo.mlr1$residuals) %>%
  rename(`MLR_RES` = `condo.mlr1.residuals`)

#Convert into sp object as spdep needs sp objects
condo_resale.sp = as_Spatial(condo_resale.res.sf)
```

We can view the residuals on the interactive map.

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21) + 
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.5) +
tm_shape(condo_resale.res.sf) +
  tm_dots(col = "MLR_RES", alpha = 0.6, style = "quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")
```

We cab see that there is some spatial autocorrelation, as we do see some potential clustering. We can verify this using a Moran's I test.

```{r}
nb = dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

```{r}
nb_lw = nb2listw(nb, style = 'W')
summary(nb_lw)
```

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

We can see the p-value is \<0.05, as such we can reject the null hypothesis of random distribution. With the observed Moran I being greater than 0, we can infer a slight cluster distribution.

## Building Hedonic Pricing Models using GWmodel

### Fixed Bandwidth

We can use *bw.gwr()* to determine the optimal fixed bandwidth.

```{r}
bw.fixed = bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +
                    PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA +
                    PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                    PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS +
                    FAMILY_FRIENDLY + FREEHOLD, 
                  data = condo_resale.sp, 
                  approach = "CV", 
                  kernel = "gaussian", 
                  adaptive = FALSE, 
                  longlat = FALSE)
```

The results shows the recommended bandwidth to be 971.3405 metres. Now we can calibrate the gwr model.

```{r}
gwr.fixed = gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +
                        PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA +
                        PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                        PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                        FAMILY_FRIENDLY + FREEHOLD, 
                      data = condo_resale.sp, 
                      bw = bw.fixed, 
                      kernel = 'gaussian', 
                      longlat = FALSE)
gwr.fixed
```

This gives us the AICc of the GWR to be 42263.36, which is significantly smaller than the global multiple linear regression model.

### Adaptive Bandwidth

We can repeat the same steps, but setting adaptive to TRUE.

```{r}
bw.adaptive = bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +
                       PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA +
                       PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH +
                       PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS +
                       FAMILY_FRIENDLY + FREEHOLD, 
                     data = condo_resale.sp, 
                     approach = "CV", 
                     kernel = "gaussian", 
                     adaptive = TRUE, 
                     longlat = FALSE)
```

This shows us the adaptive bandwidth recommended is 30. We can use this in our gwr modelling.

```{r}
gwr.adaptive = gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +
                           PROX_CHILDCARE + PROX_ELDERLYCARE + 
                           PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +
                           PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +
                           NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                         data = condo_resale.sp, 
                         bw = bw.adaptive, 
                         kernel = 'gaussian', 
                         adaptive = TRUE,
                         longlat = FALSE)
gwr.adaptive
```

This gives us the AICc of the GWR to be 41982.22, which is even smaller than the fixed bandwidth.

### Output

In addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:

-   Condition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.

-   Local R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.

-   Predicted: these are the estimated (or fitted) y values 3. computed by GWR.

-   Residuals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.

-   Coefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.

They are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called **SDF** of the output list.

We can visualise this output by converting the SDF into a sf data.frame and plotting it using *tmap().*

```{r}
condo_resale.sf.adaptive = st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs = 3414)
```

```{r}
tmap_mode("view")
```

Visualising local R2

```{r}
tm_shape(mpsz_svy21) +
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.5) +
tm_shape(condo_resale.sf.adaptive) +
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

Visualising coefficient estimates

```{r}
AREA_SQM_SE = tm_shape(mpsz_svy21) +
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.5) +
tm_shape(condo_resale.sf.adaptive) +
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))


AREA_SQM_TV = tm_shape(mpsz_svy21) +
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.5) +
tm_shape(condo_resale.sf.adaptive) +
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, ncol = 2, sync = TRUE)
```

```{r}
tmap_mode("plot")
```

Visualising URA Planning Region

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION",]) +
  tm_polygons(alpha = 0.5) +
tm_shape(condo_resale.sf.adaptive) +
  tm_bubbles(col = "Local_R2", 
             size = 0.2,
             border.col = "gray60",
             border.lwd = 1)
```
